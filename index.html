<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>TechHour @ CVTE</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <link rel="stylesheet" type="text/css" href="stylesheets/vis.css" />
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>TechHour</h1>
        <p></p>

        <hr>
        <p>CVTE中央研究院每周六11:00-12:00开的轻量级技术分享讨论会。分享内容包括但不限于：</p>

        <ul>
        <li>经典书籍 / 教程的某一章节或知识点；</li>
        <li>经典的影响力较大的论文/方法；</li>
        <li>arxiv的最新成果；</li>
        <li>CVPR / ACL / ICASSP / SIGGRAPH等比较重要的论文；</li>
        <li>提升研发效率的方法/工具；</li>
        <li>博士实习生的博士课题；</li>
        <li>外部知名专家/学者的技术分享。</li>
        </ul>
      </header>
      <section>

          <div id="timeline"></div>

          <br/><hr>

          <h4>
          <a id="CRF系列分享之最大熵模型" class="anchor" href="#CRF系列分享之最大熵模型" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>CRF系列分享之最大熵模型</h4>

          <p>主讲：李贤博士<br/>时间：2016年6月18日11:00-12:00<br/>地点：办公室大平板前广场<br/>类型：专业类/经典算法</p>

          <p>
          条件随机场（CRF）模型是在最大熵模型和隐马尔可夫模型的基础上提出的一种无向图学习模型，是一种用于标注和切分有序数据的条件概率模型。本期李博将首先讲解最大熵模型。最大熵的原理是，在已知部分知识的前提下，关于未知分布最合理的推断就是符合已知知识最不确定或最随机的推断，这是我们可以作出的唯一不偏不倚的选择，任何其它的选择都意味着我们增加了其它的 约束和假设，这些约束和假设根据我们掌握的信息无法作出。
          </p>

          <hr>

          <h4>
          <a id="深度上下文相关模型学习及场景语义解析" class="anchor" href="#深度上下文相关模型学习及场景语义解析" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>深度上下文相关模型学习及场景语义解析</h4>

          <p>主讲：林倞教授<br/>时间：2016年6月16日10:30-11:15<br/>地点：216<br/>类型：专业类/外部知名专家分享</p>

          <p>
          在图像语义标注研究中，卷积神经网络被广泛用于特征抽取以及像素级别分类，并取得了重要的进展。但是，这类方法使用卷积核来捕捉像素周边信息，仅仅利用了有限的局部上下文相关性。本报告将介绍在深度特征学习中融入全局空间上下文建模的方法，该方法利用长短期记忆递归神经网络自动学习像素之间的显示相关性，并与卷积网络联合优化，从而提高特征表达的判别性。并且围绕该方法探讨了场景理解研究中的两个新问题：1) 场景几何属性与关系解析；2) 基于彩色-深度数据的场景语义标注。    
          </p>

          <hr>

          <h4>
          <a id="Person Verification: Deep Representation Learning with Relative Distance Comparison" class="anchor" href="#Person Verification: Deep Representation Learning with Relative Distance Comparison" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Person Verification: Deep Representation Learning with Relative Distance Comparison</h4>

          <p>主讲：林倞教授<br/>时间：2016年6月16日11:15-12:00<br/>地点：216<br/>类型：专业类/外部知名专家分享</p>

          <p>
          Person verification is an important problem with many applications. Modern systems of image retrieval are often developed to verify whether input photos contain the same person or the same object. Person verification gains increasing attentions for building an intelligent video surveillance system, which are able to identify the same individual across different videos. This talks will first review several advances in the related topics including feature learning, distance similarity learning, and benchmarks; then introduce two works from my group: i) a generalized deep similarity model for cross-domain visual matching; ii) a supervised hashing framework to generate compact and bit-scalable hashing codes.</p>

          <p>
          讲者简介：

          林倞，中山大学数据科学与计算机学院教授，博士生导师，教育部超算工程软件工程研究中心副主任。2007-2009年在美国加州大学洛杉矶分校工作，2013-2014年在香港理工大学访问。长期从事视觉计算与智能感知等相关领域的研究，迄今已在权威期刊IJCV (Springer) / IEEE T-PAMI发表论文7篇，在其他IEEE 汇刊发表论文20余篇，在CVPR/NIPS/ICCV/ACM MM等顶级国际会议发表论文30余篇。获得2010年 ACM NPAR最佳论文奖，2012年Google Faculty Award，2014年ICME最佳学生论文奖。2012年入选教育部新世纪优秀人才支持计划，2013年获广东自然科学杰出青年基金。目前担任IEEE Trans. Human-Machine Systems、The Visual Computer、Neurocomputing的知名期刊的编委。
          </p>

          <hr>

          <h4>
          <a id="傅立叶变换" class="anchor" href="#傅立叶变换" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>傅立叶变换</h4>

          <p>主讲：刘荣总工<br/>时间：2016年6月8日11:00-12:00<br/>地点：702<br/>类型：专业类/经典算法</p>

          <p>傅里叶变换是信号处理与数据分析领域里最重要的算法之一。荣哥带领大家将深入探讨傅里叶级数、傅立叶变换、FFT等内容。</p>

          <hr>

          <h4>
          <a id="SVM系列分享之对偶问题" class="anchor" href="#SVM系列分享之对偶问题" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>SVM系列分享之对偶问题</h4>

          <p>主讲：张玉兵博导<br/>时间：2016年6月4日11:00-12:00<br/>地点：办公室大平板前广场<br/>类型：专业类/经典算法</p>

          <p>本期为SVM系列分享第二弹——对偶问题，我们将讨论SVM基本型的模型求解方法。</p>

          <hr>

          <h4>
          <a id="SVM系列分享之间隔和支持向量" class="anchor" href="#svm%E7%B3%BB%E5%88%97%E5%88%86%E4%BA%AB%E4%B9%8B%E9%97%B4%E9%9A%94%E5%92%8C%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>SVM系列分享之间隔和支持向量</h4>

          <p>主讲：张玉兵博导<br/>时间：2016年5月28日11:00-12:00<br/>地点：办公室大平板前广场<br/>类型：专业类/经典算法</p>

          <p>为了让大家对SVM有更深刻的理解，张博导将给大家带来SVM系列分享（参考教材：周志华的《机器学习》），内容包括（1）间隔和支持向量；（2）对偶问题；(3)SMO；（4）SVM中的核函数、软间隔与正则化。
          本次主题为间隔和支持向量。我们将讨论SVM的基本型及其划分超平面的基本原理。</p>

          <hr>

          <h4>
          <a id="脑机接口简介" class="anchor" href="#%E8%84%91%E6%9C%BA%E6%8E%A5%E5%8F%A3%E7%AE%80%E4%BB%8B" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>脑机接口简介</h4>

          <p>主讲：赵巍博士<br/<p>时间：2016年5月28日10:00-11:00<br/>地点：办公室大平板前广场<br/>类型：科普类</p>

          <p>脑机接口(Brain-Computer Interface)是一种利用大脑神经信号与外部设备直接交互（从“心想”到“事成”）的技术。那么，BCI系统是如何利用这些信号实现交互应用的呢？周六赵博给你娓娓道来。</p>

          <hr>

          <h4>
          <a id="expectationmaximization-algorithm" class="anchor" href="#expectationmaximization-algorithm" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Expectation–Maximization Algorithm</h4>

          <p>主讲：雷延强博士<br/>时间：2016年5月21日11:00-12:00<br/>地点：办公室大平板前广场<br/>类型：专业类/经典算法</p>

          <p>Expectation–Maximization Algorithm（EM算法）是常用于机器学习、计算机视觉等领域的经典算法。
          在概率参数模型含有无法观测的隐变量的情况下，如何进行参数最大似然估计/最大后验估计？
          TechHour第二弹雷博士话你知。</p>

          <hr>

          <h4>
          <a id="temporal-variance-analysis-for-action-recognition" class="anchor" href="#temporal-variance-analysis-for-action-recognition" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Temporal Variance Analysis for Action Recognition</h4>

          <p>主讲：苗捷博士<br/<p>时间：2016年5月14日11:00-12:00<br/>地点：702<br/>类型：专业类/好文面授</p>

          <p>Slow feature analysis (SFA) extracts slowly varying signals from input data and has been used to model complex cells in the primary visual cortex (V1). It transmits information to both ventral and dorsal pathways to process appearance and motion information, respectively. However, SFA only uses slowly varying features for local feature extraction, because they represent appearance information more effectively than motion information. To better utilize temporal information, we propose temporal variance analysis (TVA) as a generalization of SFA.</p>
          <hr>
      </section>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    <script src="javascripts/vis.js"></script>
    <script type="text/javascript">
      // DOM element where the Timeline will be attached
      var container = document.getElementById('timeline');

      // Create a DataSet (allows two way data-binding)
      var items = new vis.DataSet([
        {id: 1, content: 'Temporal Variance Analysis for Action Recognition', start: '2016-05-14'},
        {id: 2, content: 'Expectation–Maximization Algorithm', start: '2016-05-21'},
        {id: 3, content: '脑机接口简介', start: '2016-05-28'},
        {id: 4, content: 'SVM系列分享之间隔和支持向量', start: '2016-05-28'},
        {id: 5, content: 'SVM系列分享之对偶问题', start: '2016-06-04'},
        {id: 6, content: 'FFT', start: '2016-06-08'},
        {id: 7, content: 'Person Verification', start: '2016-06-16'},
        {id: 70, content: '深度上下文相关模型学习及场景语义解析', start: '2016-06-16'},
        {id: 71, content: 'CRF系列分享之最大熵模型', start: '2016-06-18'},
        {id: 8, content: 'SVM系列分享之SMO', start: '2016-06-25'},
        {id: 9, content: 'SVM系列分享之核函数、软间隔与正则化', start: '2016-07-02'},
      ]);

      function get_date(offset) {
        var d = new Date();
        d.setDate(d.getDate() + offset);
        var dd = d.getDate();
        if ( dd < 10 ) dd = '0' + dd;
        var mm = d.getMonth()+1;
        if ( mm < 10 ) mm = '0' + mm;
        return d.getFullYear() + '-' + mm + '-' + dd;
      }
      var options = {start: get_date(-8), end: get_date(8)};
      var timeline = new vis.Timeline(container, items, options);
    </script>
  </body>
</html>
