{
  "name": "TechHour",
  "tagline": "",
  "body": "\r\n---\r\n\r\nTechHour：研究院每周六11:00-12:00开的轻量级技术分享讨论会。\r\n\r\n分享内容偏学术，包括但不限于：\r\n* 经典书籍 / 教程的某一章节或知识点；\r\n* 经典的影响力较大的论文/方法；\r\n* arxiv的最新成果；\r\n* 会议季可以讲讲CVPR / ACL / ICASSP / SIGGRAPH等比较重要的论文；\r\n* 提升研发效率的方法/工具；\r\n* 博士实习生的博士课题；\r\n* 外部知名专家/学者的技术分享。\r\n\r\n---\r\n\r\n#### 脑机接口简介\r\n\r\n主讲：赵巍博士\r\n\r\n时间：2016年5月28日10:00-11:00\r\n\r\n地点：办公室大平板前广场\r\n\r\n类型：科普类\r\n\r\n脑机接口(Brain-Computer Interface)是一种利用大脑神经信号与外部设备直接交互（从“心想”到“事成”）的技术。那么，BCI系统是如何利用这些信号实现交互应用的呢？周六赵博给你娓娓道来。\r\n\r\n---\r\n\r\n#### SVM系列分享之间隔和支持向量\r\n\r\n主讲：张玉兵博导\r\n\r\n时间：2016年5月28日11:00-12:00\r\n\r\n地点：办公室大平板前广场\r\n\r\n类型：专业类/经典算法\r\n\r\n为了让大家对SVM有更深刻的理解，张博导将给大家带来SVM系列分享（参考教材：周志华的《机器学习》），内容包括（1）间隔和支持向量；（2）对偶问题和SMO；（3）SVM中的核函数、软间隔与正则化。\r\n本次主题为间隔和支持向量。我们将讨论SVM的基本型及其划分超平面的基本原理。\r\n\r\n---\r\n\r\n#### Expectation–Maximization Algorithm\r\n\r\n主讲：雷延强博士\r\n\r\n时间：2016年5月21日11:00-12:00\r\n\r\n地点：办公室大平板前广场\r\n\r\n类型：专业类/经典算法\r\n\r\nExpectation–Maximization Algorithm（EM算法）是常用于机器学习、计算机视觉等领域的经典算法。\r\n在概率参数模型含有无法观测的隐变量的情况下，如何进行参数最大似然估计/最大后验估计？\r\nTechHour第二弹雷博士话你知。\r\n\r\n\r\n---\r\n\r\n#### Temporal Variance Analysis for Action Recognition\r\n\r\n主讲：苗捷博士\r\n\r\n时间：2016年5月14日11:00-12:00\r\n\r\n地点：702\r\n\r\n类型：专业类/好文面授\r\n\r\nSlow feature analysis (SFA) extracts slowly varying signals from input data and has been used to model complex cells in the primary visual cortex (V1). It transmits information to both ventral and dorsal pathways to process appearance and motion information, respectively. However, SFA only uses slowly varying features for local feature extraction, because they represent appearance information more effectively than motion information. To better utilize temporal information, we propose temporal variance analysis (TVA) as a generalization of SFA.",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}